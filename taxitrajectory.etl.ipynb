{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi Trajectory Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of the Coursera, IBM Advanced Data Science Capstone Project\n",
    "Cerated by Engin Cicek, ecicek@gmail.com\n",
    "\n",
    "Data used in this Capstone Project is found on kaggle website titled as \"ECML/PKDD 15: Taxi Trajectory Prediction (I)\" \n",
    "\n",
    "Dataset can be found at : https://www.kaggle.com/c/pkdd-15-predict-taxi-service-trajectory-i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------\n",
    "\n",
    "Cehecklist for Week2:\n",
    "\n",
    "- Created an ETL Notebook\n",
    "\n",
    "- Added Data Cleansing code to the ETL Notebook\n",
    "\n",
    "- Created a Feature Creation Notebook\n",
    "\n",
    "- Transformed Features\n",
    "\n",
    "- Created additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ETL :\n",
    "\n",
    "First stage of is for the \"Extract Transform Load (ETL)\" stage of the Process Model used for this data science project.\n",
    "\n",
    "Deliverable of this notebook is the data to be used in other stages of the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "DATA CLEANSING :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1710670 entries, 0 to 1710669\n",
      "Data columns (total 9 columns):\n",
      "TRIP_ID         int64\n",
      "CALL_TYPE       object\n",
      "ORIGIN_CALL     float64\n",
      "ORIGIN_STAND    float64\n",
      "TAXI_ID         int64\n",
      "TIMESTAMP       int64\n",
      "DAY_TYPE        object\n",
      "MISSING_DATA    bool\n",
      "POLYLINE        object\n",
      "dtypes: bool(1), float64(2), int64(3), object(3)\n",
      "memory usage: 106.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,710,670 rows and 9 columns in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>DAY_TYPE</th>\n",
       "      <th>MISSING_DATA</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>788360</th>\n",
       "      <td>1387279893620000398</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20000398</td>\n",
       "      <td>1387279893</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.608725,41.147721],[-8.608644,41.147685],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782447</th>\n",
       "      <td>1387148341620000423</td>\n",
       "      <td>A</td>\n",
       "      <td>5358.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000423</td>\n",
       "      <td>1387148341</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.60832,41.152905],[-8.608311,41.152707],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511708</th>\n",
       "      <td>1382119581620000258</td>\n",
       "      <td>A</td>\n",
       "      <td>58108.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000258</td>\n",
       "      <td>1382119581</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.638479,41.162328],[-8.638362,41.162283],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931460</th>\n",
       "      <td>1389982794620000267</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>20000267</td>\n",
       "      <td>1389982794</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.64954,41.167116],[-8.649612,41.167179],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42580</th>\n",
       "      <td>1373384145620000468</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20000468</td>\n",
       "      <td>1373384145</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.606403,41.144706],[-8.606574,41.144733],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270944</th>\n",
       "      <td>1377990487620000179</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.0</td>\n",
       "      <td>20000179</td>\n",
       "      <td>1377990487</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.591229,41.162706],[-8.59104,41.162463],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166745</th>\n",
       "      <td>1375726902620000361</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20000361</td>\n",
       "      <td>1375726902</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.630712,41.154957],[-8.630712,41.154957],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388082</th>\n",
       "      <td>1398776250620000640</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>20000640</td>\n",
       "      <td>1398776250</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.610876,41.148909],[-8.611074,41.14908],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593705</th>\n",
       "      <td>1383592936620000174</td>\n",
       "      <td>A</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000174</td>\n",
       "      <td>1383592936</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.638659,41.159079],[-8.638569,41.159079],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522642</th>\n",
       "      <td>1382369466620000521</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20000521</td>\n",
       "      <td>1382369466</td>\n",
       "      <td>A</td>\n",
       "      <td>False</td>\n",
       "      <td>[[-8.608725,41.147811],[-8.608716,41.147793],[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "788360   1387279893620000398         B          NaN          27.0  20000398   \n",
       "782447   1387148341620000423         A       5358.0           NaN  20000423   \n",
       "511708   1382119581620000258         A      58108.0           NaN  20000258   \n",
       "931460   1389982794620000267         B          NaN          35.0  20000267   \n",
       "42580    1373384145620000468         B          NaN           9.0  20000468   \n",
       "270944   1377990487620000179         B          NaN          56.0  20000179   \n",
       "166745   1375726902620000361         B          NaN          12.0  20000361   \n",
       "1388082  1398776250620000640         B          NaN          14.0  20000640   \n",
       "593705   1383592936620000174         A       2002.0           NaN  20000174   \n",
       "522642   1382369466620000521         B          NaN          27.0  20000521   \n",
       "\n",
       "          TIMESTAMP DAY_TYPE  MISSING_DATA  \\\n",
       "788360   1387279893        A         False   \n",
       "782447   1387148341        A         False   \n",
       "511708   1382119581        A         False   \n",
       "931460   1389982794        A         False   \n",
       "42580    1373384145        A         False   \n",
       "270944   1377990487        A         False   \n",
       "166745   1375726902        A         False   \n",
       "1388082  1398776250        A         False   \n",
       "593705   1383592936        A         False   \n",
       "522642   1382369466        A         False   \n",
       "\n",
       "                                                  POLYLINE  \n",
       "788360   [[-8.608725,41.147721],[-8.608644,41.147685],[...  \n",
       "782447   [[-8.60832,41.152905],[-8.608311,41.152707],[-...  \n",
       "511708   [[-8.638479,41.162328],[-8.638362,41.162283],[...  \n",
       "931460   [[-8.64954,41.167116],[-8.649612,41.167179],[-...  \n",
       "42580    [[-8.606403,41.144706],[-8.606574,41.144733],[...  \n",
       "270944   [[-8.591229,41.162706],[-8.59104,41.162463],[-...  \n",
       "166745   [[-8.630712,41.154957],[-8.630712,41.154957],[...  \n",
       "1388082  [[-8.610876,41.148909],[-8.611074,41.14908],[-...  \n",
       "593705   [[-8.638659,41.159079],[-8.638569,41.159079],[...  \n",
       "522642   [[-8.608725,41.147811],[-8.608716,41.147793],[...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRIP_ID is the unique identifier (primary key) for this table. It is actually the combination of TIMESTAMP and TAXI ID columns for the related row (It is one of the ways used for generating row identifiers).\n",
    "\n",
    "I will go through each other columns one by one in UNIVARIATE ANALYSIS below for better understanding of the data and for checking whether any cleaning is needed for data validity and integrity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "UNIVARIATE ANALYSIS\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALL_TYPE Column :\n",
    "\n",
    "Description of the Column(as given in Data Desciption at the web address of data) :\n",
    "\n",
    "It identifies the way used to demand this service. It may contain one of three possible values:\n",
    "\n",
    "- ‘A’ if this trip was dispatched from the central;\n",
    "\n",
    "- ‘B’ if this trip was demanded directly to a taxi driver on a specific stand;\n",
    "\n",
    "- ‘C’ otherwise (i.e. a trip demanded on a random street).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    817881\n",
       "C    528019\n",
       "A    364770\n",
       "Name: CALL_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CALL_TYPE'].value_counts(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CALL_TYPE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALL_TYPE column is filled with Categorical Nominal Values\n",
    "\n",
    "The is no null value.\n",
    "\n",
    "The most common is the Stand_Based calls, followed by Random-street calls as the second most common and last one is the taxi-cnetral based calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ORIGIN_CALL Column :\n",
    "\n",
    "Description of the Column:\n",
    "\n",
    "It contains an unique identifier for each phone number which was used to demand, at least, one service.\n",
    "\n",
    "It identifies the trip’s customer if CALL_TYPE=’A’. Otherwise, it assumes a NULL value;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57105"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['ORIGIN_CALL'].unique())-1 #minus 1 is for null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are 57,105 unique customers that used taxi-central for calling a taxi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1345900"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ORIGIN_CALL'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1,345,900 null values in this column but these do not have to be missing values. Because, only trips with taxi station calls can have customer ids (phone numbers). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify whether this column has values consistently as it is described so, I will alseo run 2 checks:\n",
    "\n",
    "- Check-1: There should not be any rows with null value in ORIGIN_CALL column if the trip is recorded as type 'A' Call\n",
    "\n",
    "- Check-2: There should not be any rows with non-null value in ORIGIN_CALL column if the trip is recorded as type 'B' or 'C' Call_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "check1=df.loc[(df['ORIGIN_CALL'].notnull())& (df['CALL_TYPE']!='A'),'TRIP_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: TRIP_ID, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check2=df.loc[(df['ORIGIN_CALL'].isnull())& (df['CALL_TYPE']=='A'),'TRIP_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: TRIP_ID, dtype: int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another way of checking both. Number of type-A call types + number of null values in ORIGIN_CALL columns shoul be equal to total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.loc[:,'CALL_TYPE']=='A'])+df['ORIGIN_CALL'].isnull().sum()-len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks show that there is not any inconsistency about what the ORIGIN_CALL tells us.\n",
    "\n",
    "Values are float but obviously there is no need to check for outliers. \n",
    "\n",
    "We don't have any other information (like age, gender etc.) about the customers other than their phone number within this identifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "We now know that there are 57,105 unique customers used taxi-central for calling taxi for their trips.\n",
    "We also know that there are 364,770 trips started with calls made with the taxi_central (from CALL_TYPE calumn's category counts)\n",
    "\n",
    "Then, below is the avarage number of calls a customer made to the tavi-central (for only those using taxi-central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.387706855791962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df.loc[:,'CALL_TYPE']=='A'])/(len(df['ORIGIN_CALL'].unique())-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, below is the maximum number of calls received from a customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(df['ORIGIN_CALL'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15782822052252105"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(df['ORIGIN_CALL'].value_counts())/len(df[df.loc[:,'CALL_TYPE']=='A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks that almost 16% of the calls to the taxi-central are made by one customer.\n",
    "\n",
    "This customer may be a firm, airport or big hotel. But, still this amount of calls from one location does not really make sense, since that would make aproximately 158 calls/ day and 6 calls/ hour in average (it is a 365-day data).\n",
    "\n",
    "Looking at these averages, this calumn does not look reliable for futher analysis and model building.\n",
    "\n",
    "It is better consider droping this column from the data that will be used for further stages and training model.\n",
    "\n",
    "For now I will keep it and give my final decision after looking at its correlation with trip distance etc.\n",
    "\n",
    "At this step, I still don't have the starting_locations of the trips. They need to be extracted from POLYLINE column that contains all location information of the total trip. I will come back to this point after I generate new columns (starting_location, end_location of the trips) from POLYLINE column. Then I will do one more round of checking for data cleansing needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------\n",
    "\n",
    "ORIGIN_STAND :\n",
    "\n",
    "Description of the Column:\n",
    "\n",
    "It contains an unique identifier for each phone number which was used to demand, at least, one service.\n",
    "\n",
    "It identifies the trip’s customer if CALL_TYPE=’A’. Otherwise, it assumes a NULL value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['ORIGIN_STAND'].unique())-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are 63 unique taxi stands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904091"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ORIGIN_STAND'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 904,084 null values in this column but these do not have to be missing values. Because, only trips from taxi stands can have taxistand IDs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to verify whether this column has values as it is described so, I will run 2 checks:\n",
    "\n",
    "- There should not be any rows with null value in ORIGIN_STAND column if the trip is recorded as type 'B' Call\n",
    "\n",
    "- There should not be any rows with non-null value in ORIGIN_STAND column if the trip is recorded as type 'A' or 'C' Call_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "check3=df.loc[(df['ORIGIN_STAND'].notnull())& (df['CALL_TYPE']!='B'),'TRIP_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: TRIP_ID, dtype: int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "check4=df.loc[(df['ORIGIN_STAND'].isnull())& (df['CALL_TYPE']=='B'),'TRIP_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11302"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11302"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another way of doing Check4\n",
    "len(df[df.loc[:,'CALL_TYPE']=='B'])+df['ORIGIN_STAND'].isnull().sum()-len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First check has passed and show that there is not any row with Origin_Stand value is null and Call_Type is 'B' (which is consistency with what the ORIGIN_CALL column is supposed to give)\n",
    "\n",
    "However, the second check has not passed and tells us that there are non-null values is ORIGIN_STAND calumn even the trip is not recorded as 'B' as CALL_TYPE.\n",
    "\n",
    "This may be the result of :\n",
    "\n",
    "- either misrecording CALL_TYPE as A or C instead of B\n",
    "\n",
    "- or misrecording ORIGIN_STAND as some value (taxi stand id) instead of recording it as NULL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006606768108401971"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check4)/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These rows that are inconsistent in terms of CALL_TYPE and ORIGIN_STAND make up 0.6% of the total data which can be considered very few and can be cancelled out from the data.\n",
    "\n",
    "However, I will check if these rows are actually belong to taxi stand calls (Type B) by cross-checking the the starting_point of the trip with the location of the taxi stand. I can do this by looking at another row that is known to be a taxi stand with the same ID.\n",
    "\n",
    "At this step, I still don't have the starting_locations of the trips. They need to be extracted from POLYLINE column that contains all location information of the total trip. I will come back to this point after I generate new columns (starting_location, end_location of the trips) from POLYLINE column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________\n",
    "\n",
    "TAXI ID :\n",
    "\n",
    "Description of the Column:\n",
    "\n",
    "It contains an unique identifier for the taxi driver that performed each trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "448"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['TAXI_ID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TAXI_ID'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 448 unique taxi drivers within the data. No missing value.\n",
    "\n",
    "I don't think that the taxi driver would have any effect on taxi_call times, customer's destinations etc.\n",
    "\n",
    "However, travelled distance between two same start and end locations may differ depending on the taxi driver (that happens in some cities). \n",
    "\n",
    "Therefore, this column can be used in testing this hyphotesis during further analysis and model building steps.\n",
    "\n",
    "I will set forward my questions and related hyphotesis afterwards (Effect of taxi driver on travel distance and time is one of my potential questions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "DAY_TYPE :\n",
    "\n",
    "Description of the Column:\n",
    "\n",
    "It identifies the daytype of the trip’s start. It assumes one of three possible values:\n",
    "\n",
    "- 'B’ if this trip started on a holiday or any other special day (i.e. extending holidays, floating holidays, etc.);\n",
    "- ‘C’ if the trip started on a day before a type-B day;\n",
    "- ‘A’ otherwise (i.e. a normal day, workday or weekend)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    1710670\n",
       "Name: DAY_TYPE, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DAY_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DAY_TYPE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks that this row has only A-type Days and no missing value. This is no variation in column values and this does not make any contribution to any analysis and model to be built. Therefore, I will just drop this column !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('DAY_TYPE', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MISSING_DATA :\n",
    "\n",
    "Description of the Column:\n",
    "\n",
    "It is FALSE when the GPS data stream is complete and TRUE whenever one (or more) locations are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1710660\n",
       "True          10\n",
       "Name: MISSING_DATA, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MISSING_DATA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are very few non-null value in this column and it is impossible to find which GPS coordinate is missing during the trip. Therefore, I will just cancel out these 10 rows from the data and drop this column since there will be no variation within this column !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[df['MISSING_DATA']==False,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('MISSING_DATA', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "TIMESTAMP :\n",
    "\n",
    "Description of the Column: Unix Timestamp (in seconds). It identifies the trip’s start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['TIMESTAMP'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no NULL value in any row of this Column.\n",
    "\n",
    "I find it more useful to add a new column in datetime type format and drop TIMESTAMP column extract month, day of the week, hour of the day from this new column for further analysis and model building steps. I will do this in the next step which will be on Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "POLYLINE Column :\n",
    "\n",
    "It contains a list of GPS coordinates (i.e. WGS84 format) mapped as a string. The beginning and the end of the string are identified with brackets (i.e. [ and ], respectively). Each pair of coordinates is also identified by the same brackets as [LONGITUDE, LATITUDE]. This list contains one pair of coordinates for each 15 seconds of trip. The last list item corresponds to the trip’s destination while the first one represents its start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POLYLINE'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no null value in this column. However, in order to see if there is inconsistent data in this column, I need to transfrom this column and extract coordinates into new columns. I will do this in the Feature Engineering step and do another round of Data Cleansing afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploading current df to object store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRIP_ID</th>\n",
       "      <th>CALL_TYPE</th>\n",
       "      <th>ORIGIN_CALL</th>\n",
       "      <th>ORIGIN_STAND</th>\n",
       "      <th>TAXI_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>POLYLINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26584</th>\n",
       "      <td>1373092588620000142</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000142</td>\n",
       "      <td>1373092588</td>\n",
       "      <td>[[-8.613639,41.147019],[-8.613621,41.146992],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564008</th>\n",
       "      <td>1383126568620000159</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20000159</td>\n",
       "      <td>1383126568</td>\n",
       "      <td>[[-8.585694,41.148837],[-8.585685,41.148819],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082006</th>\n",
       "      <td>1392963878620000900</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20000900</td>\n",
       "      <td>1392963878</td>\n",
       "      <td>[[-8.610525,41.145174],[-8.610741,41.145201],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687892</th>\n",
       "      <td>1385463188620000042</td>\n",
       "      <td>A</td>\n",
       "      <td>14133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000042</td>\n",
       "      <td>1385463188</td>\n",
       "      <td>[[-8.625096,41.158242],[-8.625078,41.15826],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796861</th>\n",
       "      <td>1387439140620000080</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>20000080</td>\n",
       "      <td>1387439140</td>\n",
       "      <td>[[-8.621109,41.161014],[-8.621091,41.161023],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326256</th>\n",
       "      <td>1379061842620000086</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20000086</td>\n",
       "      <td>1379061842</td>\n",
       "      <td>[[-8.628831,41.161005],[-8.628651,41.160879],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506108</th>\n",
       "      <td>1382083858620000686</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20000686</td>\n",
       "      <td>1382083858</td>\n",
       "      <td>[[-8.627859,41.158008],[-8.62893,41.15889],[-8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303075</th>\n",
       "      <td>1378612738620000075</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20000075</td>\n",
       "      <td>1378612738</td>\n",
       "      <td>[[-8.61264,41.146056],[-8.612298,41.145957],[-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5184</th>\n",
       "      <td>1372749214620000076</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000076</td>\n",
       "      <td>1372749214</td>\n",
       "      <td>[[-8.604666,41.169933],[-8.604666,41.169951],[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441241</th>\n",
       "      <td>1399595560620000451</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000451</td>\n",
       "      <td>1399595560</td>\n",
       "      <td>[[-8.603046,41.183838],[-8.603028,41.183847],[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     TRIP_ID CALL_TYPE  ORIGIN_CALL  ORIGIN_STAND   TAXI_ID  \\\n",
       "26584    1373092588620000142         C          NaN           NaN  20000142   \n",
       "564008   1383126568620000159         B          NaN          15.0  20000159   \n",
       "1082006  1392963878620000900         B          NaN          57.0  20000900   \n",
       "687892   1385463188620000042         A      14133.0           NaN  20000042   \n",
       "796861   1387439140620000080         B          NaN          51.0  20000080   \n",
       "326256   1379061842620000086         B          NaN          21.0  20000086   \n",
       "506108   1382083858620000686         B          NaN          13.0  20000686   \n",
       "303075   1378612738620000075         B          NaN          23.0  20000075   \n",
       "5184     1372749214620000076         C          NaN           NaN  20000076   \n",
       "1441241  1399595560620000451         C          NaN           NaN  20000451   \n",
       "\n",
       "          TIMESTAMP                                           POLYLINE  \n",
       "26584    1373092588  [[-8.613639,41.147019],[-8.613621,41.146992],[...  \n",
       "564008   1383126568  [[-8.585694,41.148837],[-8.585685,41.148819],[...  \n",
       "1082006  1392963878  [[-8.610525,41.145174],[-8.610741,41.145201],[...  \n",
       "687892   1385463188  [[-8.625096,41.158242],[-8.625078,41.15826],[-...  \n",
       "796861   1387439140  [[-8.621109,41.161014],[-8.621091,41.161023],[...  \n",
       "326256   1379061842  [[-8.628831,41.161005],[-8.628651,41.160879],[...  \n",
       "506108   1382083858  [[-8.627859,41.158008],[-8.62893,41.15889],[-8...  \n",
       "303075   1378612738  [[-8.61264,41.146056],[-8.612298,41.145957],[-...  \n",
       "5184     1372749214  [[-8.604666,41.169933],[-8.604666,41.169951],[...  \n",
       "1441241  1399595560  [[-8.603046,41.183838],[-8.603028,41.183847],[...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
